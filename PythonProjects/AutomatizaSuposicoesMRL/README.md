# Projeto: Infer√™ncia sobre os Fatores que Influenciam na Taxa de Ocupa√ß√£o de Resid√™ncias usando Regress√£o Linear

O objetivo deste projeto √© responder √† seguinte pergunta: **Quais fatores mais influenciam na taxa de ocupa√ß√£o de resid√™ncias?**

## Objetivo Final

Ao final, vamos checar e automatizar as valida√ß√µes das suposi√ß√µes do MRL: linearidade, independ√™ncia, homocedasticidade, normalidade dos erros, e multicolinearidade.

## Descri√ß√£o do Projeto

Este projeto traz um extenso e detalhado trabalho de modelagem estat√≠stica e demonstra na pr√°tica como validar as suposi√ß√µes para a regress√£o linear, como interpretar os resultados, as decis√µes que devem ser tomadas durante o processo de an√°lise e como automatizar algumas tarefas. Ele aborda na pr√°tica todo o processo de ci√™ncia de dados, com √™nfase na modelagem estat√≠stica.

Trabalharemos com dados reais dispon√≠veis publicamente sobre atributos de resid√™ncias de uma cidade norte-americana. Passaremos por todo o processo de ci√™ncia de dados, com √™nfase na modelagem estat√≠stica e diversas t√©cnicas de an√°lise e interpreta√ß√£o ser√£o usadas. Por fim, criaremos fun√ß√µes em Python para automatizar a valida√ß√£o das suposi√ß√µes da regress√£o linear.

## Sobre a Regress√£o Linear

A regress√£o linear √© um m√©todo estat√≠stico usado para modelar a rela√ß√£o linear entre uma vari√°vel dependente e uma ou mais vari√°veis independentes. Para usar a regress√£o linear de forma eficaz, certas suposi√ß√µes devem ser satisfeitas sobre os dados e o modelo que est√° sendo usado.

### Suposi√ß√µes da Regress√£o Linear

1. **Linearidade:** A rela√ß√£o entre a vari√°vel dependente e as vari√°veis independentes √© linear.
2. **Independ√™ncia dos Erros:** Os erros (res√≠duos) s√£o independentes entre si e n√£o est√£o correlacionados com as vari√°veis independentes.
3. **Homocedasticidade:** A vari√¢ncia dos erros √© constante em todas as vari√°veis independentes.
4. **Normalidade:** Os erros s√£o normalmente distribu√≠dos.
5. **N√£o Multicolinearidade:** As vari√°veis independentes n√£o s√£o altamente correlacionadas umas com as outras.

√â importante verificar se essas suposi√ß√µes s√£o satisfeitas antes de usar um modelo de regress√£o linear, pois a viola√ß√£o dessas suposi√ß√µes pode levar a resultados incorretos ou tendenciosos.

## Automa√ß√£o das Valida√ß√µes

Vamos automatizar essas valida√ß√µes atrav√©s de testes com fun√ß√µes Python.
Resumo dos Resultados das T√©cnicas de Valida√ß√£o
1. Linearidade
Teste: Gr√°ficos de dispers√£o e teste linear_rainbow.
Explica√ß√£o:
Gr√°ficos de Dispers√£o: Visualiza√ß√£o da rela√ß√£o entre a vari√°vel dependente 
ùëå
Y e as vari√°veis independentes 
ùëã
X para verificar a linearidade.
Teste linear_rainbow: Verifica a linearidade da regress√£o usando uma divis√£o dos dados em segmentos e testando a varia√ß√£o dos res√≠duos.
Interpreta√ß√£o:
p-valor < 0.05: Rejeitamos a hip√≥tese nula de linearidade. A rela√ß√£o pode n√£o ser linear.
p-valor >= 0.05: Falhamos em rejeitar a hip√≥tese nula de linearidade. A rela√ß√£o provavelmente √© linear.
2. Independ√™ncia dos Erros
Teste: Teste de Durbin-Watson.
Explica√ß√£o:
Teste de Durbin-Watson: Verifica a presen√ßa de autocorrela√ß√£o nos res√≠duos da regress√£o. Valores pr√≥ximos de 2 indicam independ√™ncia dos erros.
Interpreta√ß√£o:
0 < d < 1.5: Evid√™ncia de autocorrela√ß√£o positiva nos erros. Suposi√ß√£o n√£o satisfeita.
1.5 <= d <= 2.5: N√£o h√° evid√™ncia de autocorrela√ß√£o. Suposi√ß√£o satisfeita.
2.5 < d < 4: Evid√™ncia de autocorrela√ß√£o negativa nos erros. Suposi√ß√£o n√£o satisfeita.
3. Homocedasticidade
Teste: Teste de Goldfeld-Quandt ou teste de Breusch-Pagan.
Explica√ß√£o:
Teste de Goldfeld-Quandt: Divide os dados em dois grupos e compara a vari√¢ncia dos res√≠duos para verificar homocedasticidade.
Teste de Breusch-Pagan: Avalia se a vari√¢ncia dos res√≠duos √© constante usando uma regress√£o auxiliar.
Interpreta√ß√£o:
p-valor < 0.05: Rejeitamos a hip√≥tese nula de homocedasticidade. A vari√¢ncia dos erros n√£o √© constante.
p-valor >= 0.05: Falhamos em rejeitar a hip√≥tese nula de homocedasticidade. A vari√¢ncia dos erros √© constante.
4. Normalidade dos Erros
Teste: Histogramas, QQ plots, e teste de Shapiro-Wilk.
Explica√ß√£o:
Histograma: Visualiza√ß√£o da distribui√ß√£o dos res√≠duos.
QQ Plot: Compara os quantis dos res√≠duos com os quantis de uma distribui√ß√£o normal.
Teste de Shapiro-Wilk: Teste estat√≠stico que verifica se os res√≠duos seguem uma distribui√ß√£o normal.
Interpreta√ß√£o:
p-valor < 0.05: Rejeitamos a hip√≥tese nula de normalidade. Os res√≠duos n√£o seguem uma distribui√ß√£o normal.
p-valor >= 0.05: Falhamos em rejeitar a hip√≥tese nula de normalidade. Os res√≠duos seguem uma distribui√ß√£o normal.
5. Aus√™ncia de Multicolinearidade
Teste: Fator de Infla√ß√£o da Vari√¢ncia (VIF).
Explica√ß√£o:
VIF: Mede quanto a vari√¢ncia de um coeficiente de regress√£o √© inflada devido √† correla√ß√£o entre as vari√°veis independentes.
Interpreta√ß√£o:
VIF = 1: N√£o h√° correla√ß√£o entre a vari√°vel independente e as outras vari√°veis independentes.
1 < VIF < 5: Correla√ß√£o moderada, geralmente aceit√°vel.
VIF > 5: Correla√ß√£o alta, pode indicar multicolinearidade.
VIF > 10: Correla√ß√£o muito alta, indica problemas s√©rios de multicolinearidade.
